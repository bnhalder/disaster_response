{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data():\n",
    "    conn = create_engine('sqlite:///../data/DisasterResponse.db')\n",
    "    df = pd.read_sql_table('disaster_messages_table', conn)\n",
    "    #conn = sqlite3.connect('InsertDatabaseName.db')\n",
    "    #df = pd.read_sql(\"SELECT * FROM InsertTableName\", conn)\n",
    "    X = df.message.values\n",
    "    labels = df.columns[4:]\n",
    "    y = df[labels].values\n",
    "    return X, y, labels\n",
    "\n",
    "X, y, labels = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
       "       'missing_people', 'refugees', 'death', 'other_aid',\n",
       "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
       "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
       "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
       "       'other_weather', 'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a086d3b9495b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genre'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'related'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'news'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.groupby(['genre', 'related']).count()['message']['news'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "category_counts = list()\n",
    "category_counts_news = list()\n",
    "for label in labels:\n",
    "    try:\n",
    "        category_counts.append(df.groupby(label).count()['message'][1])\n",
    "        category_counts_news.append(df.groupby(['genre', label]).count()['message']['news'][1])\n",
    "    except:\n",
    "        category_counts.append(0)\n",
    "        category_counts_news.append(0)\n",
    "print(category_counts)\n",
    "print(category_counts_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/bhalder/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/bhalder/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# download necessary NLTK data\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "- You'll find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "vect = CountVectorizer(tokenizer=tokenize)\n",
    "tfidf = TfidfTransformer()\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# train classifier\n",
    "X_train_counts = vect.fit_transform(X_train)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_counts)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# predict on test data\n",
    "X_test_counts = vect.transform(X_test)\n",
    "X_test_tfidf = tfidf.transform(X_test_counts)\n",
    "y_pred = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = Pipeline([\n",
    "#    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#    ('tfidf', TfidfTransformer()),\n",
    "#    ('clf', MultiOutputClassifier(estimator=RandomForestClassifier()))\n",
    "#])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the accuracy, precision and recall on both the training set and the test set. You can use sklearn's `classification_report` function here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_test = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for all the categories are as follows - \n",
      "related: 0.7966127555691181\n",
      "request: 0.878547451937748\n",
      "offer: 0.9952700640830028\n",
      "aid_related: 0.6981995727799817\n",
      "medical_help: 0.9231003967043027\n",
      "medical_products: 0.9533109551418981\n",
      "search_and_rescue: 0.9734513274336283\n",
      "security: 0.9798596277082697\n",
      "military: 0.9670430271589868\n",
      "child_alone: 1.0\n",
      "water: 0.9412572474824534\n",
      "food: 0.9070796460176991\n",
      "shelter: 0.9189807750991761\n",
      "clothing: 0.9884040280744584\n",
      "money: 0.9769606347268843\n",
      "missing_people: 0.9882514494964907\n",
      "refugees: 0.9668904485810192\n",
      "death: 0.9563625267012511\n",
      "other_aid: 0.8643576441867562\n",
      "infrastructure_related: 0.9346963686298444\n",
      "transport: 0.9516325907842539\n",
      "buildings: 0.9517851693622216\n",
      "electricity: 0.9780286847726579\n",
      "tools: 0.9938968568812938\n",
      "hospitals: 0.9909978638999084\n",
      "shops: 0.9957277998169057\n",
      "aid_centers: 0.988556606652426\n",
      "other_infrastructure: 0.9540738480317363\n",
      "weather_related: 0.8051571559353067\n",
      "floods: 0.9270674397314617\n",
      "storm: 0.9102837961550199\n",
      "fire: 0.9909978638999084\n",
      "earthquake: 0.9336283185840708\n",
      "cold: 0.9783338419285932\n",
      "other_weather: 0.9436985047299359\n",
      "direct_report: 0.8458956362526702\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Scores for all the categories are as follows - \")\n",
    "for i, label in enumerate(labels):\n",
    "    print(\"{}: {}\".format(label, accuracy_score(y_test[:, i], y_pred_test[:, i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.885865418849499\n",
      "0.259231003967043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "print(accuracy_score(y_train, y_pred_train))\n",
    "print(accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "#print(f1_score(y_train, y_pred_train))\n",
    "#print(f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- Scores for trainig set ------------------------\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.99      1.00      1.00     15061\n",
      "               request       1.00      0.93      0.96      3360\n",
      "                 offer       1.00      0.78      0.88        87\n",
      "           aid_related       1.00      0.96      0.98      8192\n",
      "          medical_help       1.00      0.83      0.91      1583\n",
      "      medical_products       1.00      0.81      0.90      1001\n",
      "     search_and_rescue       1.00      0.78      0.88       553\n",
      "              security       1.00      0.73      0.84       341\n",
      "              military       1.00      0.79      0.88       644\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       1.00      0.90      0.95      1225\n",
      "                  food       1.00      0.92      0.96      2199\n",
      "               shelter       1.00      0.88      0.94      1764\n",
      "              clothing       1.00      0.81      0.89       330\n",
      "                 money       1.00      0.74      0.85       451\n",
      "        missing_people       1.00      0.78      0.88       222\n",
      "              refugees       1.00      0.78      0.88       660\n",
      "                 death       1.00      0.85      0.92       903\n",
      "             other_aid       1.00      0.84      0.91      2560\n",
      "infrastructure_related       1.00      0.76      0.86      1281\n",
      "             transport       1.00      0.80      0.89       881\n",
      "             buildings       1.00      0.82      0.90      1019\n",
      "           electricity       1.00      0.81      0.89       386\n",
      "                 tools       1.00      0.72      0.84       119\n",
      "             hospitals       1.00      0.66      0.80       224\n",
      "                 shops       1.00      0.80      0.89        92\n",
      "           aid_centers       1.00      0.63      0.77       234\n",
      "  other_infrastructure       1.00      0.75      0.86       853\n",
      "       weather_related       1.00      0.94      0.97      5439\n",
      "                floods       1.00      0.88      0.93      1611\n",
      "                 storm       1.00      0.91      0.96      1788\n",
      "                  fire       1.00      0.76      0.86       223\n",
      "            earthquake       1.00      0.93      0.96      1830\n",
      "                  cold       1.00      0.81      0.89       388\n",
      "         other_weather       1.00      0.77      0.87      1007\n",
      "         direct_report       1.00      0.91      0.95      3792\n",
      "\n",
      "           avg / total       1.00      0.91      0.95     62303\n",
      "\n",
      "------------------- Scores for testing set ------------------------\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.85      0.90      0.87      5032\n",
      "               request       0.81      0.37      0.51      1114\n",
      "                 offer       0.00      0.00      0.00        31\n",
      "           aid_related       0.74      0.40      0.52      2668\n",
      "          medical_help       0.41      0.01      0.03       501\n",
      "      medical_products       0.62      0.05      0.09       312\n",
      "     search_and_rescue       0.00      0.00      0.00       171\n",
      "              security       0.00      0.00      0.00       130\n",
      "              military       0.50      0.00      0.01       216\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.87      0.16      0.27       447\n",
      "                  food       0.80      0.21      0.33       724\n",
      "               shelter       0.72      0.06      0.10       550\n",
      "              clothing       0.40      0.03      0.05        75\n",
      "                 money       1.00      0.01      0.03       153\n",
      "        missing_people       0.00      0.00      0.00        76\n",
      "              refugees       0.25      0.00      0.01       215\n",
      "                 death       0.73      0.03      0.05       291\n",
      "             other_aid       0.47      0.03      0.05       886\n",
      "infrastructure_related       0.17      0.00      0.00       424\n",
      "             transport       0.59      0.03      0.06       320\n",
      "             buildings       0.38      0.01      0.02       314\n",
      "           electricity       1.00      0.01      0.03       146\n",
      "                 tools       0.00      0.00      0.00        40\n",
      "             hospitals       0.00      0.00      0.00        59\n",
      "                 shops       0.00      0.00      0.00        28\n",
      "           aid_centers       0.00      0.00      0.00        75\n",
      "  other_infrastructure       0.20      0.00      0.01       298\n",
      "       weather_related       0.86      0.37      0.52      1858\n",
      "                floods       0.88      0.14      0.24       544\n",
      "                 storm       0.79      0.14      0.24       655\n",
      "                  fire       0.00      0.00      0.00        59\n",
      "            earthquake       0.87      0.36      0.51       625\n",
      "                  cold       0.50      0.01      0.01       142\n",
      "         other_weather       0.50      0.01      0.03       369\n",
      "         direct_report       0.79      0.29      0.43      1283\n",
      "\n",
      "           avg / total       0.71      0.38      0.43     20831\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------- Scores for trainig set ------------------------\")\n",
    "print(classification_report(y_train, y_pred_train, target_names=labels))\n",
    "print(\"------------------- Scores for testing set ------------------------\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "parameters = {\n",
    "        #'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "        #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "        #'vect__max_features': (None, 5000, 10000),\n",
    "        #'tfidf__use_idf': (True, False),\n",
    "        'clf__n_estimators': [100],\n",
    "        #'clf__min_samples_split': [2, 3, 4]\n",
    "    }\n",
    "\n",
    "scorer = make_scorer(classification_report)\n",
    "\n",
    "grid_obj = GridSearchCV(pipeline, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_fit = grid_obj.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_clf = grid_fit.best_estimator_\n",
    "y_pred_train = grid_fit.predict(X_train)\n",
    "y_pred_test = grid_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_train, y_pred_train))\n",
    "print(accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------- Scores for trainig set ------------------------\")\n",
    "print(classification_report(y_train, y_pred_train, target_names=labels))\n",
    "print(\"------------------- Scores for testing set ------------------------\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///../data/DisasterResponse.db')\n",
    "df = pd.read_sql_table('disaster_messages_table', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26215, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(grid_obj, 'saved_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
